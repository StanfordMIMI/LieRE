# optimizer:
#   class_path: torch.optim.Adam
#   init_args:
#     lr: 1E-4

model:
  class_path: LiereImageClassification
  init_args:
    learning_rate: 1E-4
    imsize: 224
    model_architecture: liere
    model_size: base
    patch_size: [16, 16]
    num_classes: 1000
    input_dimensionality: 2
    emb_dropout: 0.1
    attn_dropout: 0.1
    # input_type: IMAGES
    num_channels: 3
    rotary_embedding_per_layer: True
    rotary_embedding_per_head: True

trainer: 
  max_epochs: 200
  num_sanity_val_steps: 0
  accumulate_grad_batches: 2
  default_root_dir: "."
  strategy:
    class_path: lightning.pytorch.strategies.DDPStrategy
    init_args:
      find_unused_parameters: false  # or true, depending on your needs
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "."
        save_last: True
        save_top_k: 1
        every_n_train_steps: 50
  logger:
    init_args:
      name: "liere_imagenet"
      project: "imagenet"
      entity: "brophie"
    # callbacks:
  #   - class_path: FLOPsAnalysisCallback
  #     init_args:
  #       input_shape: [1, 3, 224, 224]

# lr_scheduler:
#   class_path: torch.optim.lr_scheduler.CosineAnnealingLR
#   init_args:
#     T_max: 200

data:
  class_path: Imagenet
  init_args:
    data_dir: "/dataNAS/people/sostm/data/gcp_imagenet/sostm_imagenet"
    per_device_batch_size: 64 # for A100 40GBs
    imsize: 224 #192
